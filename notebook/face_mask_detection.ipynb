{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv5 Face Mask Detection üß™\n",
    "This notebook walks through loading a trained YOLOv5 model and testing it on images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b329703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import torch\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473b221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(kaggle_json_path, download_path=\"../data\"):\n",
    "    os.environ['KAGGLE_CONFIG_DIR'] = os.path.dirname(kaggle_json_path)\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_download_files(\"andrewmvd/face-mask-detection\", path=download_path, unzip=True)\n",
    "    print(\"‚úÖ Dataset downloaded and extracted to\", download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ecbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_dataset(\n",
    "    annotations_dir='../data/annotations',\n",
    "    images_dir='../data/images',\n",
    "    output_dir='../dataset'\n",
    "):\n",
    "    labels_map = {\n",
    "        'with_mask': 'with_mask',\n",
    "        'without_mask': 'without_mask',\n",
    "        'mask_weared_incorrect': 'mask_weared_incorrect'\n",
    "    }\n",
    "\n",
    "    # Create a class folder if it doesn't already exist\n",
    "    for label in labels_map.values():\n",
    "        os.makedirs(os.path.join(output_dir, label), exist_ok=True)\n",
    "\n",
    "    # Read the XML file and move the images to the class folder as labeled\n",
    "    for xml_file in os.listdir(annotations_dir):\n",
    "        if not xml_file.endswith('.xml'):\n",
    "            continue\n",
    "\n",
    "        xml_path = os.path.join(annotations_dir, xml_file)\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        filename = root.find('filename').text\n",
    "        label = root.find('object').find('name').text\n",
    "\n",
    "        if label in labels_map:\n",
    "            src_image_path = os.path.join(images_dir, filename)\n",
    "            dst_image_path = os.path.join(output_dir, labels_map[label], filename)\n",
    "\n",
    "            if os.path.exists(src_image_path):\n",
    "                shutil.copy(src_image_path, dst_image_path)\n",
    "\n",
    "    print(\"‚úÖ The dataset has been moved to the per-class folder in the:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f5c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape=(224, 224, 3), num_classes=3):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=input_shape))\n",
    "\n",
    "    # Freeze base model\n",
    "    base_model.trainable = True\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a6780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, val_gen):\n",
    "    val_gen.reset()\n",
    "    preds = model.predict(val_gen, verbose=1)\n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "    y_true = val_gen.classes\n",
    "    class_labels = list(val_gen.class_indices.keys())\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=val_gen.class_indices, yticklabels=val_gen.class_indices)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "def evaluate_model_normalized(model, val_gen):\n",
    "    val_gen.reset()\n",
    "    preds = model.predict(val_gen, verbose=1)\n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "    y_true = val_gen.classes\n",
    "    class_labels = list(val_gen.class_indices.keys())\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb088e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(y_true, y_pred, class_indices, file_path=\"../visualizations/predictions.csv\"):\n",
    "    class_labels = list(class_indices.keys())\n",
    "    inverse_map = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Actual': [inverse_map[i] for i in y_true],\n",
    "        'Predicted': [inverse_map[i] for i in y_pred]\n",
    "    })\n",
    "\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"üìÑ Saved prediction results to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(image_path, model, class_indices, img_size=(224, 224)):\n",
    "    img = tf.keras.utils.load_img(image_path, target_size=img_size)\n",
    "    img_array = tf.keras.utils.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    class_labels = list(class_indices.keys())\n",
    "\n",
    "    print(f\"üìå Image: {image_path}\")\n",
    "    print(f\"Predicted: {class_labels[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530ab47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "kaggle_json_path = \"../kaggle.json\"  # Adjust path if needed\n",
    "if not os.path.exists(\"../data/annotations\"):  # simple check if already extracted\n",
    "    download_dataset(kaggle_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1235648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "organize_dataset()\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    '../dataset/',  # fixed path\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    '../dataset/',  # fixed path\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    \"../dataset/\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = create_model(input_shape=img_size + (3,), num_classes=3)\n",
    "\n",
    "# Recompile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08797391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "if not os.path.exists(\"../models\"):\n",
    "    os.makedirs(\"../models\")\n",
    "    \n",
    "checkpoint_cb = ModelCheckpoint(\"../models/best_mask_detector.h5\", save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "earlystop_cb = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=3,\n",
    "    callbacks=[checkpoint_cb, earlystop_cb]\n",
    ")\n",
    "\n",
    "model.save(\"../models/mask_detector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5cb179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "if not os.path.exists(\"../visualizations\"):\n",
    "    os.makedirs(\"../visualizations\")\n",
    "\n",
    "plot_training(history)\n",
    "evaluate_model(model, test_gen)\n",
    "evaluate_model_normalized(model, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86503e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take y_true and y_pred from prediction\n",
    "test_gen.reset()\n",
    "preds = model.predict(test_gen, verbose=1)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_true = test_gen.classes\n",
    "\n",
    "save_predictions(y_true, y_pred, val_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fec3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_gen)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e6c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_single_image(\"../test/sample_test.png\", model, train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOLOv5 TESTING ===\n",
    "\n",
    "print(\"\\nüîç Running YOLOv5 detection on sample image...\")\n",
    "\n",
    "# Load YOLOv5 pretrained model\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'custom', path='../models/yolov5/yolov5s.pt')\n",
    "\n",
    "# Load a sample image from the dataset (with_mask as example)\n",
    "sample_images = glob.glob(\"../dataset/with_mask/*.jpg\") + glob.glob(\"../dataset/with_mask/*.png\")\n",
    "if sample_images:\n",
    "    test_img = sample_images[0]\n",
    "    print(\"üñºÔ∏è Image path:\", test_img)\n",
    "    results = yolo_model(test_img)\n",
    "    results.print()\n",
    "    results.show()\n",
    "else:\n",
    "    print(\"‚ùå No image found in ../dataset/with_mask/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3053eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for category in ['with_mask', 'without_mask', 'mask_weared_incorrect']:\n",
    "    sample_images = glob.glob(f\"../dataset/{category}/*.jpg\") + glob.glob(f\"../dataset/{category}/*.png\")\n",
    "    if sample_images:\n",
    "        test_img = random.choice(sample_images)\n",
    "        print(f\"\\nüñºÔ∏è Testing image from '{category}': {test_img}\")\n",
    "        results = yolo_model(test_img)\n",
    "        results.print()\n",
    "        results.show()\n",
    "    else:\n",
    "        print(f\"‚ùå No image found in ../dataset/{category}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
