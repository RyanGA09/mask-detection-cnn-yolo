{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv5 Face Mask Detection ðŸ§ª\n",
    "This notebook walks through loading a trained YOLOv5 model and testing it on images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Upload kaggle.json via file picker ---\n",
    "def upload_kaggle_json():\n",
    "    print(\"Pilih file kaggle.json untuk autentikasi Kaggle API...\")\n",
    "    Tk().withdraw()  # sembunyikan jendela utama tkinter\n",
    "    file_path = askopenfilename(title=\"Pilih file kaggle.json\", filetypes=[(\"JSON files\", \"*.json\")])\n",
    "    if not file_path:\n",
    "        print(\"File kaggle.json tidak dipilih. Program dihentikan.\")\n",
    "        exit(1)\n",
    "    print(f\"File kaggle.json dipilih: {file_path}\")\n",
    "    # Set config dir ke folder file json\n",
    "    os.environ['KAGGLE_CONFIG_DIR'] = os.path.dirname(file_path)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1235648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Download dataset dari Kaggle ---\n",
    "def download_dataset():\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    print(\"Download dataset Face Mask Detection dari Kaggle...\")\n",
    "    api.dataset_download_files('andrewmvd/face-mask-detection', path='datasets', unzip=True)\n",
    "    print(\"Download selesai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Prepare data generators (preprocessing & augmentation) ---\n",
    "def create_data_generators(img_size=(128,128), batch_size=32):\n",
    "    base_dir = os.path.join('datasets', 'images')\n",
    "\n",
    "    # Dataset sudah terstruktur folder: train/validation belum ada, jadi kita pakai ImageDataGenerator dengan validation_split\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=0.2,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=15,\n",
    "        shear_range=0.1,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    train_gen = datagen.flow_from_directory(\n",
    "        base_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_gen = datagen.flow_from_directory(\n",
    "        base_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_gen, val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08797391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Build CNN model ---\n",
    "def build_model(input_shape=(128,128,3), num_classes=3):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(128, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5cb179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Plot training history ---\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12,5))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6: Evaluate model performance on validation data ---\n",
    "def evaluate_model(model, val_gen):\n",
    "    val_gen.reset()\n",
    "    preds = model.predict(val_gen, verbose=1)\n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "    y_true = val_gen.classes\n",
    "    class_labels = list(val_gen.class_indices.keys())\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e61a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main pipeline ---\n",
    "def main():\n",
    "    # Upload file kaggle.json\n",
    "    upload_kaggle_json()\n",
    "\n",
    "    # Download dataset dan ekstrak\n",
    "    download_dataset()\n",
    "\n",
    "    # Prepare data generators\n",
    "    train_gen, val_gen = create_data_generators()\n",
    "\n",
    "    # Build model\n",
    "    model = build_model()\n",
    "\n",
    "    # Train model\n",
    "    print(\"Mulai training...\")\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=10\n",
    "    )\n",
    "\n",
    "    # Plot training history\n",
    "    plot_history(history)\n",
    "\n",
    "    # Evaluate model\n",
    "    evaluate_model(model, val_gen)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
